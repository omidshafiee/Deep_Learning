{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a04f3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b314912",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"D:\",os.sep, \"Datasets\",\"Stock\",\"h1\")#, \"*.csv\")\n",
    "# os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9103c84",
   "metadata": {},
   "source": [
    "    # read all data into 1 dataframed\n",
    "df_list = []\n",
    "for (root, dirs ,files) in os.walk(path):\n",
    "    # df_list = (pd.read_csv(os.path.join(path,f), delimiter='\\t') for file in files)\n",
    "    # big_df= pd.concat(df_list, ignore_index=True)\n",
    "    for f in files:\n",
    "        df_tmp = pd.read_csv(os.path.join(path,f), delimiter='\\t')\n",
    "        df_tmp['Instrument'] = f.split('_')[0]\n",
    "        df_list.append(df_tmp)\n",
    "        print(f.split('_')[0] + ' has updated!')\n",
    "\n",
    "df= pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1858cd",
   "metadata": {},
   "source": [
    "# read all data into 1 dataframed\n",
    "df_list = []\n",
    "for (root, dirs ,files) in os.walk(path):\n",
    "    # df_list = (pd.read_csv(os.path.join(path,f), delimiter='\\t') for file in files)\n",
    "    # big_df= pd.concat(df_list, ignore_index=True)\n",
    "    for f in files:\n",
    "        df_tmp = pd.read_csv(os.path.join(path,f), delimiter='\\t')\n",
    "        df_tmp['Instrument'] = f.split('_')[0]\n",
    "        df_list.append(df_tmp)\n",
    "        print(f.split('_')[0] + ' has updated!')\n",
    "\n",
    "df= pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "df.to_csv('../Dataset/stock.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a05d6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read all data and create low price dataframe into 1 dataframed\n",
    "df= pd.DataFrame()\n",
    "for (root, dirs ,files) in os.walk(path):\n",
    "    # df_list = (pd.read_csv(os.path.join(path,f), delimiter='\\t') for file in files)\n",
    "    # big_df= pd.concat(df_list, ignore_index=True)\n",
    "    for f in files:\n",
    "        df_tmp = pd.read_csv(os.path.join(path,f), delimiter='\\t')\n",
    "        Instrument = f.split('_')[0] \n",
    "        Instrument = Instrument[:3] + '-' + Instrument[3:]\n",
    "        df_tmp.set_index('Time', inplace=True)\n",
    "        \n",
    "        df_tmp.rename(columns={\"Close\":f\"{Instrument}_Close\", \"Volume\":f\"{Instrument}_Volume\"}, inplace=True)\n",
    "        df_tmp = df_tmp[[f\"{Instrument}_Close\", f\"{Instrument}_Volume\"]]\n",
    "        \n",
    "        \n",
    "        df = df.join(df_tmp, how='right')\n",
    "        \n",
    "        \n",
    "        print(Instrument + ' has updated!')\n",
    "    \n",
    "\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12346f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Empty DataFrame"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "756599ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n",
    "# Visually check for null values\n",
    "# sns.heatmap(df.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebb14f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "757bb76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EURGBP_Low</th>\n",
       "      <th>EURUSD_Low</th>\n",
       "      <th>GBPUSD_Low</th>\n",
       "      <th>USDJPY_Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-07-24 18:00:00</td>\n",
       "      <td>0.67010</td>\n",
       "      <td>0.6701</td>\n",
       "      <td>0.66966</td>\n",
       "      <td>0.67000</td>\n",
       "      <td>15421</td>\n",
       "      <td>0.66966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-07-24 19:00:00</td>\n",
       "      <td>0.67000</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>0.66985</td>\n",
       "      <td>0.67045</td>\n",
       "      <td>84904</td>\n",
       "      <td>0.66985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-07-24 20:00:00</td>\n",
       "      <td>0.67045</td>\n",
       "      <td>0.6706</td>\n",
       "      <td>0.66990</td>\n",
       "      <td>0.67010</td>\n",
       "      <td>33690</td>\n",
       "      <td>0.66990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-07-24 21:00:00</td>\n",
       "      <td>0.67010</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>0.66990</td>\n",
       "      <td>0.67050</td>\n",
       "      <td>8960</td>\n",
       "      <td>0.66990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-07-24 22:00:00</td>\n",
       "      <td>0.67050</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>0.67032</td>\n",
       "      <td>0.67040</td>\n",
       "      <td>16738</td>\n",
       "      <td>0.67032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400042</th>\n",
       "      <td>2023-08-01 00:00:00</td>\n",
       "      <td>142.32400</td>\n",
       "      <td>142.5010</td>\n",
       "      <td>142.25400</td>\n",
       "      <td>142.49600</td>\n",
       "      <td>11202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400043</th>\n",
       "      <td>2023-08-01 01:00:00</td>\n",
       "      <td>142.49400</td>\n",
       "      <td>142.7840</td>\n",
       "      <td>142.43400</td>\n",
       "      <td>142.75300</td>\n",
       "      <td>14572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400044</th>\n",
       "      <td>2023-08-01 02:00:00</td>\n",
       "      <td>142.76500</td>\n",
       "      <td>142.7960</td>\n",
       "      <td>142.53200</td>\n",
       "      <td>142.57300</td>\n",
       "      <td>11623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400045</th>\n",
       "      <td>2023-08-01 03:00:00</td>\n",
       "      <td>142.57400</td>\n",
       "      <td>142.7260</td>\n",
       "      <td>142.53800</td>\n",
       "      <td>142.66700</td>\n",
       "      <td>7933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400046</th>\n",
       "      <td>2023-08-01 04:00:00</td>\n",
       "      <td>142.66800</td>\n",
       "      <td>142.8430</td>\n",
       "      <td>142.64900</td>\n",
       "      <td>142.72100</td>\n",
       "      <td>8360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400047 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Time       Open      High        Low      Close  \\\n",
       "0       2007-07-24 18:00:00    0.67010    0.6701    0.66966    0.67000   \n",
       "1       2007-07-24 19:00:00    0.67000    0.6707    0.66985    0.67045   \n",
       "2       2007-07-24 20:00:00    0.67045    0.6706    0.66990    0.67010   \n",
       "3       2007-07-24 21:00:00    0.67010    0.6707    0.66990    0.67050   \n",
       "4       2007-07-24 22:00:00    0.67050    0.6707    0.67032    0.67040   \n",
       "...                     ...        ...       ...        ...        ...   \n",
       "400042  2023-08-01 00:00:00  142.32400  142.5010  142.25400  142.49600   \n",
       "400043  2023-08-01 01:00:00  142.49400  142.7840  142.43400  142.75300   \n",
       "400044  2023-08-01 02:00:00  142.76500  142.7960  142.53200  142.57300   \n",
       "400045  2023-08-01 03:00:00  142.57400  142.7260  142.53800  142.66700   \n",
       "400046  2023-08-01 04:00:00  142.66800  142.8430  142.64900  142.72100   \n",
       "\n",
       "        Volume  EURGBP_Low  EURUSD_Low  GBPUSD_Low  USDJPY_Low  \n",
       "0        15421     0.66966         NaN         NaN         NaN  \n",
       "1        84904     0.66985         NaN         NaN         NaN  \n",
       "2        33690     0.66990         NaN         NaN         NaN  \n",
       "3         8960     0.66990         NaN         NaN         NaN  \n",
       "4        16738     0.67032         NaN         NaN         NaN  \n",
       "...        ...         ...         ...         ...         ...  \n",
       "400042   11202         NaN         NaN         NaN     142.254  \n",
       "400043   14572         NaN         NaN         NaN     142.434  \n",
       "400044   11623         NaN         NaN         NaN     142.532  \n",
       "400045    7933         NaN         NaN         NaN     142.538  \n",
       "400046    8360         NaN         NaN         NaN     142.649  \n",
       "\n",
       "[400047 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30fd35a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['EUR-GBP_Close', 'EUR-USD_Close', 'GBP-USD_Close'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MEHDI~1.OMI\\AppData\\Local\\Temp/ipykernel_13080/4167971246.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EUR-GBP_Close'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'EUR-USD_Close'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GBP-USD_Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1372\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['EUR-GBP_Close', 'EUR-USD_Close', 'GBP-USD_Close'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "df[['EUR-GBP_Close', 'EUR-USD_Close', 'GBP-USD_Close']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a3c820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence length (timeframe length)\n",
    "period_len = 60\n",
    "# step which predict after timefreame has trained (arbitrary value)\n",
    "next_item_predict = 3\n",
    "# Instrument to predict\n",
    "predict_ratio = 'GBP-USD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "129f9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose next nth step as future value to predict and concat to df\n",
    "# its a dummy variable just to use in calculation\n",
    "df['future'] = df[f'{predict_ratio}_Close'].shift(-next_item_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "894872de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine if price goes up(expensive) or not\n",
    "# this function is simple as returns 1 in case of price increament which means take buy position and vice versa\n",
    "# we may develop the function as return differentiaion value, so the problem must consideredc as regression\n",
    "\n",
    "def price_classification(current, future):\n",
    "    if float(current) > float(future):\n",
    "        return 0 \n",
    "    else:\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ceda9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = list(map(price_classification, df[f'{predict_ratio}_Close'], df['future']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60b3f74",
   "metadata": {},
   "source": [
    "## Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1bddfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = sorted(df.index.values)\n",
    "# last 5% of timesteps\n",
    "last_5_pcent = sorted(df.index.values)[-int(0.05 * len(time_steps))]\n",
    "\n",
    "#create validation data, which index is gt last 5 percent of data\n",
    "validation_df = df[(df.index) >= last_5_pcent]\n",
    "#main data turns to first 95% of timeframes\n",
    "df =  df[(df.index) < last_5_pcent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e1c7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns\n",
    "def preproc_data(df:pd.DataFrame):\n",
    "    \n",
    "    if 'future' in df.columns:\n",
    "        df.drop('future', axis=1, inplace=True)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col != 'target': # normolize all columns, except the target\n",
    "            # normalize each instrument. calculate relations based on percent change rather than value\n",
    "            df[col].pct_change()\n",
    "            df.dropna(inplace=True)\n",
    "            df[col] = preprocessing.scale(df[col].values) # Scale between 0 and 1\n",
    "        \n",
    "    df.dropna(inplace=True) # cleanup again, because nan may generate during percentage change ops\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66adc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = df.copy()\n",
    "df = df_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47289584",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ffee2",
   "metadata": {},
   "source": [
    "## Create sequences and Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f66787f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data as timeseries\n",
    "\n",
    "sequential_data = []\n",
    "prev_days = deque(maxlen=period_len)\n",
    "\n",
    "for i in df.values:\n",
    "    prev_days.append([n for n in i[:-1]]) #keep all except the target\n",
    "    if len(prev_days) == period_len:\n",
    "        # insert every indivudual date prices, for period length days in this case 60 days\n",
    "        # i[-1] is the target of 60th day target (last day of period)\n",
    "        sequential_data.append([np.array(prev_days), i[-1]])\n",
    "\n",
    "\n",
    "# now shuffle data\n",
    "random.shuffle(sequential_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe6094",
   "metadata": {},
   "source": [
    "## Balance data with down sampling (buy/sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d6d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "buys = [] # to store buy data\n",
    "sells = [] # to store sell data\n",
    "\n",
    "for seq, target in sequential_data:\n",
    "    if target == 0: # if its sell\n",
    "        sells.append([seq, target]) \n",
    "    elif target == 1: # if its buy\n",
    "        buys.append([seq, target])\n",
    "        \n",
    "random.shuffle(buys) # shuffle buy list\n",
    "random.shuffle(sells) # shuffle buy list\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8689a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea21b446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
