{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e1f8c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff61b2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active processing device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# use cuda if available or else use cpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Active processing device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43801ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cuda.is_available()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bbb6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "n_epochs =15\n",
    "n_classes =10\n",
    "batch_size = 128\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faf1fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset in pytorch\n",
    "train_dataset = torchvision.datasets.MNIST('../data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST('../data/', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c021bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0c3000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dense1 = nn.Linear(12*12*64, 128)\n",
    "        self.dense2 = nn.Linear(128, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.view(-1, 12*12*64) # same as flat layer\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.dense2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e467d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], step [100/469],                    Loss:0.2784\n",
      "Epoch [1/15], step [200/469],                    Loss:0.3376\n",
      "Epoch [1/15], step [300/469],                    Loss:0.0731\n",
      "Epoch [1/15], step [400/469],                    Loss:0.0864\n",
      "Epoch [2/15], step [100/469],                    Loss:0.1008\n",
      "Epoch [2/15], step [200/469],                    Loss:0.1180\n",
      "Epoch [2/15], step [300/469],                    Loss:0.0268\n",
      "Epoch [2/15], step [400/469],                    Loss:0.1210\n",
      "Epoch [3/15], step [100/469],                    Loss:0.1316\n",
      "Epoch [3/15], step [200/469],                    Loss:0.0256\n",
      "Epoch [3/15], step [300/469],                    Loss:0.0913\n",
      "Epoch [3/15], step [400/469],                    Loss:0.0565\n",
      "Epoch [4/15], step [100/469],                    Loss:0.1045\n",
      "Epoch [4/15], step [200/469],                    Loss:0.0803\n",
      "Epoch [4/15], step [300/469],                    Loss:0.0999\n",
      "Epoch [4/15], step [400/469],                    Loss:0.1363\n",
      "Epoch [5/15], step [100/469],                    Loss:0.0672\n",
      "Epoch [5/15], step [200/469],                    Loss:0.0623\n",
      "Epoch [5/15], step [300/469],                    Loss:0.0751\n",
      "Epoch [5/15], step [400/469],                    Loss:0.0337\n",
      "Epoch [6/15], step [100/469],                    Loss:0.0176\n",
      "Epoch [6/15], step [200/469],                    Loss:0.0427\n",
      "Epoch [6/15], step [300/469],                    Loss:0.0087\n",
      "Epoch [6/15], step [400/469],                    Loss:0.0205\n",
      "Epoch [7/15], step [100/469],                    Loss:0.1099\n",
      "Epoch [7/15], step [200/469],                    Loss:0.0771\n",
      "Epoch [7/15], step [300/469],                    Loss:0.0299\n",
      "Epoch [7/15], step [400/469],                    Loss:0.0439\n",
      "Epoch [8/15], step [100/469],                    Loss:0.0201\n",
      "Epoch [8/15], step [200/469],                    Loss:0.0554\n",
      "Epoch [8/15], step [300/469],                    Loss:0.0464\n",
      "Epoch [8/15], step [400/469],                    Loss:0.0087\n",
      "Epoch [9/15], step [100/469],                    Loss:0.0417\n",
      "Epoch [9/15], step [200/469],                    Loss:0.0819\n",
      "Epoch [9/15], step [300/469],                    Loss:0.0080\n",
      "Epoch [9/15], step [400/469],                    Loss:0.0077\n",
      "Epoch [10/15], step [100/469],                    Loss:0.0317\n",
      "Epoch [10/15], step [200/469],                    Loss:0.0482\n",
      "Epoch [10/15], step [300/469],                    Loss:0.0294\n",
      "Epoch [10/15], step [400/469],                    Loss:0.0129\n",
      "Epoch [11/15], step [100/469],                    Loss:0.0199\n",
      "Epoch [11/15], step [200/469],                    Loss:0.0042\n",
      "Epoch [11/15], step [300/469],                    Loss:0.0442\n",
      "Epoch [11/15], step [400/469],                    Loss:0.0031\n",
      "Epoch [12/15], step [100/469],                    Loss:0.0117\n",
      "Epoch [12/15], step [200/469],                    Loss:0.0632\n",
      "Epoch [12/15], step [300/469],                    Loss:0.0034\n",
      "Epoch [12/15], step [400/469],                    Loss:0.0132\n",
      "Epoch [13/15], step [100/469],                    Loss:0.0213\n",
      "Epoch [13/15], step [200/469],                    Loss:0.0495\n",
      "Epoch [13/15], step [300/469],                    Loss:0.0223\n",
      "Epoch [13/15], step [400/469],                    Loss:0.0062\n",
      "Epoch [14/15], step [100/469],                    Loss:0.0442\n",
      "Epoch [14/15], step [200/469],                    Loss:0.0225\n",
      "Epoch [14/15], step [300/469],                    Loss:0.0582\n",
      "Epoch [14/15], step [400/469],                    Loss:0.0039\n",
      "Epoch [15/15], step [100/469],                    Loss:0.0127\n",
      "Epoch [15/15], step [200/469],                    Loss:0.0957\n",
      "Epoch [15/15], step [300/469],                    Loss:0.0103\n",
      "Epoch [15/15], step [400/469],                    Loss:0.0563\n"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "ceriterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = ceriterion(outputs, labels)\n",
    "        \n",
    "        # Back propagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{n_epochs}], step [{i+1}/{total_step}],\\\n",
    "                    Loss:{loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f147a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model test\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bcb0042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on 10k images:  98.46%\n",
      "AUC: 99.14%\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "y_true = []\n",
    "\n",
    "# set model to evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _ , predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        detached_pred = predicted.detach().cpu().numpy()\n",
    "        detached_label = labels.detach().cpu().numpy()\n",
    "        for f in range(0, len(detached_pred)):\n",
    "            preds.append(detached_pred[f])\n",
    "            y_true.append(detached_label[f])\n",
    "    \n",
    "    print(f'Test Accuracy on 10k images: {correct/total: .2%}')\n",
    "    \n",
    "        \n",
    "    preds = np.eye(n_classes)[preds]\n",
    "    y_true = np.eye(n_classes)[y_true]\n",
    "    auc = roc_auc_score(preds, y_true)\n",
    "    print(f'AUC: {auc:.2%}')\n",
    "    \n",
    "# save model checkpoint\n",
    "torch.save(model.state_dict(), 'pytorch_mnist_cnn.ckpt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812aaf24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8438f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fba7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a13ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
